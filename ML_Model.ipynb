{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04961652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense , Dropout\n",
    "import os, string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "991a30ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 128\n",
    "# Step 1 - Building the CNN\n",
    "\n",
    "# Initializing the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# First convolution layer and pooling\n",
    "classifier.add(Convolution2D(32, (3, 3), input_shape=(sz, sz, 1), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Second convolution layer and pooling\n",
    "classifier.add(Convolution2D(32, (3, 3), activation='relu'))\n",
    "# input_shape is going to be the pooled feature maps from the previous convolution layer\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "# Flattening the layers\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Adding a fully connected layer\n",
    "#units changed 128 to 400\n",
    "classifier.add(Dense(units=400, activation='relu'))\n",
    "classifier.add(Dropout(0.40))\n",
    "#units changed 96 to 800\n",
    "classifier.add(Dense(units=800, activation='relu'))\n",
    "classifier.add(Dropout(0.40))\n",
    "classifier.add(Dense(units=64, activation='relu'))\n",
    "classifier.add(Dense(units=26, activation='softmax')) # softmax for more than 2\n",
    "\n",
    "# Compiling the CNN\n",
    "classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) # categorical_crossentropy for more than 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e91e09ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 126, 126, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 63, 63, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 61, 61, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 30, 30, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 28800)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 400)               11520400  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 400)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 800)               320800    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 800)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                51264     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 26)                1690      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,903,722\n",
      "Trainable params: 11,903,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Step 2 - Preparing the train/test data and training the model\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85770880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=30, # rotate the image 30 degrees\n",
    "        width_shift_range=0.1, # Shift the pic width by a max of 10%\n",
    "        height_shift_range=0.1, # Shift the pic height by a max of 10%\n",
    "        rescale=1/255, # Rescale the image by normalzing it.\n",
    "        shear_range=0.2, # Shear means cutting away part of the image (max 20%)\n",
    "        zoom_range=0.2, # Zoom in by 20% max\n",
    "        horizontal_flip=True, # Allo horizontal flipping\n",
    "        fill_mode='nearest' # Fill in missing pixels with the nearest filled value\n",
    "        )\n",
    "test_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                  shear_range=0.2,\n",
    "                                  zoom_range=0.2,\n",
    "                                  horizontal_flip=True,\n",
    "                                  width_shift_range=0.1,\n",
    "                                  height_shift_range=0.1,\n",
    "                                  fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58f031a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13000 images belonging to 26 classes.\n",
      "Found 5200 images belonging to 26 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('./ProcessedData/train',\n",
    "                                                 target_size=(sz, sz),\n",
    "                                                 batch_size=10,\n",
    "                                                 color_mode='grayscale',\n",
    "                                                 class_mode='categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('./ProcessedData/test',\n",
    "                                            target_size=(sz , sz),\n",
    "                                            batch_size=10,\n",
    "                                            color_mode='grayscale',\n",
    "                                            class_mode='categorical') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4ab8c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 0,\n",
       " 'B': 1,\n",
       " 'C': 2,\n",
       " 'D': 3,\n",
       " 'E': 4,\n",
       " 'F': 5,\n",
       " 'G': 6,\n",
       " 'H': 7,\n",
       " 'I': 8,\n",
       " 'J': 9,\n",
       " 'K': 10,\n",
       " 'L': 11,\n",
       " 'M': 12,\n",
       " 'N': 13,\n",
       " 'O': 14,\n",
       " 'P': 15,\n",
       " 'Q': 16,\n",
       " 'R': 17,\n",
       " 'S': 18,\n",
       " 'T': 19,\n",
       " 'U': 20,\n",
       " 'V': 21,\n",
       " 'W': 22,\n",
       " 'X': 23,\n",
       " 'Y': 24,\n",
       " 'Z': 25}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40339f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 0,\n",
       " 'B': 1,\n",
       " 'C': 2,\n",
       " 'D': 3,\n",
       " 'E': 4,\n",
       " 'F': 5,\n",
       " 'G': 6,\n",
       " 'H': 7,\n",
       " 'I': 8,\n",
       " 'J': 9,\n",
       " 'K': 10,\n",
       " 'L': 11,\n",
       " 'M': 12,\n",
       " 'N': 13,\n",
       " 'O': 14,\n",
       " 'P': 15,\n",
       " 'Q': 16,\n",
       " 'R': 17,\n",
       " 'S': 18,\n",
       " 'T': 19,\n",
       " 'U': 20,\n",
       " 'V': 21,\n",
       " 'W': 22,\n",
       " 'X': 23,\n",
       " 'Y': 24,\n",
       " 'Z': 25}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af3fda0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "449/449 [==============================] - 71s 157ms/step - loss: 2.2133 - accuracy: 0.3216 - val_loss: 0.9288 - val_accuracy: 0.7121\n",
      "Epoch 2/10\n",
      "449/449 [==============================] - 70s 155ms/step - loss: 0.8676 - accuracy: 0.7165 - val_loss: 0.4691 - val_accuracy: 0.8521\n",
      "Epoch 3/10\n",
      "449/449 [==============================] - 70s 155ms/step - loss: 0.5615 - accuracy: 0.8176 - val_loss: 0.3826 - val_accuracy: 0.8816\n",
      "Epoch 4/10\n",
      "449/449 [==============================] - 69s 153ms/step - loss: 0.4097 - accuracy: 0.8630 - val_loss: 0.2451 - val_accuracy: 0.9195\n",
      "Epoch 5/10\n",
      "449/449 [==============================] - 69s 154ms/step - loss: 0.3284 - accuracy: 0.8976 - val_loss: 0.2457 - val_accuracy: 0.9211\n",
      "Epoch 6/10\n",
      "449/449 [==============================] - 69s 154ms/step - loss: 0.3043 - accuracy: 0.9038 - val_loss: 0.2007 - val_accuracy: 0.9389\n",
      "Epoch 7/10\n",
      "449/449 [==============================] - 69s 154ms/step - loss: 0.2644 - accuracy: 0.9118 - val_loss: 0.1944 - val_accuracy: 0.9389\n",
      "Epoch 8/10\n",
      "449/449 [==============================] - 68s 152ms/step - loss: 0.2442 - accuracy: 0.9205 - val_loss: 0.1893 - val_accuracy: 0.9484\n",
      "Epoch 9/10\n",
      "449/449 [==============================] - 69s 154ms/step - loss: 0.2104 - accuracy: 0.9314 - val_loss: 0.1905 - val_accuracy: 0.9595\n",
      "Epoch 10/10\n",
      "449/449 [==============================] - 69s 153ms/step - loss: 0.1813 - accuracy: 0.9437 - val_loss: 0.2282 - val_accuracy: 0.9463\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2445c4bb4c0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(\n",
    "        training_set,\n",
    "        steps_per_epoch=449, \n",
    "        epochs=10,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=190)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "1a816059",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_file = './ProcessedData/Test/J/90.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "74807635",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "78e9c99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = image.load_img(test_file,target_size=(128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "b2ed817e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = image.img_to_array(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "23b7f3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = cv2.cvtColor(np.array(test_img),cv2.COLOR_RGB2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "3e39d378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "42239362",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = np.expand_dims(test_img, axis=0)\n",
    "test_img = test_img/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "5fd9a8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_prob = classifier.predict(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "8222ab08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.0770412e-18, 1.5377906e-09, 1.6252721e-16, 2.1262241e-17,\n",
       "        6.0253824e-14, 1.4252166e-16, 9.7562177e-22, 4.0637791e-18,\n",
       "        2.9627875e-18, 1.0000000e+00, 7.5908945e-14, 4.3521851e-08,\n",
       "        4.3753969e-09, 4.3914494e-09, 6.9203264e-16, 2.1222082e-14,\n",
       "        5.3748894e-11, 1.4949746e-11, 2.0978647e-17, 7.2470747e-16,\n",
       "        4.8569466e-15, 1.9685978e-13, 2.9278693e-17, 3.4860140e-10,\n",
       "        2.5016305e-11, 4.8639676e-10]], dtype=float32)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "93b8babc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(prediction_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "97e64488",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = list(string.ascii_uppercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "43dcfcaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'J'"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes[np.argmax(prediction_prob)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eecb2763",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model\n",
    "import os\n",
    "if not os.path.exists(\"./Model\"):\n",
    "    os.mkdir(\"./Model\")\n",
    "classifier.save(\"./Model/Sign_classifier.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4d6acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_Json = classifier.to_json()\n",
    "with open(\"./Model/classifier_json.json\", \"w\") as json_file:\n",
    "    json_file.write(classifier_Json)\n",
    "print('json model saved')\n",
    "classifier.save_weights('./Model/classifier_weights.h5')\n",
    "print('Weights saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e13cbd",
   "metadata": {},
   "source": [
    "# Classifier Building - Completed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
